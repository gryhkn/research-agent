import requests
import json
from langchain.prompts import PromptTemplate
from langchain.agents import AgentType, Tool, initialize_agent
from langchain.chat_models import ChatOpenAI
from langchain.prompts import MessagesPlaceholder
from langchain.memory import ConversationSummaryBufferMemory
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.summarize import load_summarize_chain
from langchain.tools import Tool
import trafilatura
import streamlit as st
from langchain.schema import SystemMessage
import os
from dotenv import load_dotenv
from elevenlabs import generate

load_dotenv()
serper_api_key = os.getenv("SERP_API_KEY")
elevenlabs_api_key = os.getenv("ELEVENLABS_API_KEY")


def web_search(search_term):
    api_endpoint = "https://google.serper.dev/search"

    # request parameters
    payload = json.dumps({
        "q": search_term
    })

    headers = {
        'X-API-KEY': serper_api_key,
        'Content-Type': 'application/json'
    }

    # search api
    response = requests.request("POST", api_endpoint, headers=headers, data=payload)

    if response.ok:
        search_results = response.json()
        print("Search Results:", search_results)

        return search_results
    else:
        print(f"Error occurred: {response.status_code}")
        return None


def extract_and_summarize_content(objective: str, website_url: str):
    print("Extracting content from website...")

    # web iÃ§eriÄŸini al
    downloaded = trafilatura.fetch_url(website_url)

    # trafilatura ile text'i Ã§Ä±kar
    extracted_text = trafilatura.extract(downloaded)

    if extracted_text:
        print("Extracted Content:", extracted_text)

        # Check if the text length exceeds a certain threshold
        if len(extracted_text) > 10000:
            summarized_content = summary(objective, extracted_text)
            return summarized_content
        else:
            return extracted_text
    else:
        print(f"Failed to extract content from the URL: {website_url}")


def summary(objective, content):
    llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo-16k-0613")

    text_splitter = RecursiveCharacterTextSplitter(
        separators=["\n\n", "\n"], chunk_size=10000, chunk_overlap=500)
    docs = text_splitter.create_documents([content])
    map_prompt = """
    AÅŸaÄŸÄ±daki metni {objective} iÃ§in Ã¶zetle:
    "{text}"
    Ã–ZET:
    """
    map_prompt_template = PromptTemplate(
        template=map_prompt, input_variables=["text", "objective"])

    summary_chain = load_summarize_chain(
        llm=llm,
        chain_type='map_reduce',
        map_prompt=map_prompt_template,
        combine_prompt=map_prompt_template,
        verbose=True
    )

    output = summary_chain.run(input_documents=docs, objective=objective)

    return output


tools = [
    Tool.from_function(
        func=web_search,
        name="Search",

        description= "Mevcut olaylar ve veriler hakkÄ±nda sorularÄ± yanÄ±tlamak iÃ§in kullanÄ±lÄ±r. Hedefe yÃ¶nelik sorular sorun"
    ),
    Tool.from_function(
        func=lambda objective, url: extract_and_summarize_content(objective, url),
        name="ScrapeWebsite",
        description="Bir web sitesi URL'inden veri almak iÃ§in kullanÄ±lÄ±r; hem URL'i hem de amacÄ±nÄ±zÄ± bu fonksiyona yazÄ±n."
    )
]

system_message = SystemMessage(
    content="""
            Sen dÃ¼nyanÄ±n en iyi araÅŸtÄ±rmacÄ±sÄ±sÄ±n. Sana verilen konuyu detaylÄ±ca araÅŸtÄ±rÄ±r ve gerÃ§ek verilere dayanarak
            sonuÃ§lar Ã¼retirsin. Asla ama asla uydurma ve gerÃ§ek olmayan bilgiler vermez ve araÅŸtÄ±rmanÄ± destekleyecek en gerÃ§ek verileri toplamaya Ã§alÄ±ÅŸÄ±rsÄ±n.

            LÃ¼tfen yukarÄ±daki uyarÄ±larÄ± dikkate al ve aÅŸaÄŸÄ±daki kurallara uy:
            1/ Sana verilen gÃ¶re hakkÄ±nda mÃ¼mkÃ¼n olduÄŸunca Ã§ok bilgi topla ve yeterince araÅŸtÄ±rma yap.
            2/ Ä°lgili baÄŸlantÄ±lar ve makalelerin URL'leri varsa, daha fazla bilgi toplamak iÃ§in bunlarÄ± da tara.
            3/ Tarama ve arama sonrasÄ±nda, "TopladÄ±ÄŸÄ±m verilere dayanarak araÅŸtÄ±rma kalitesini artÄ±rmak iÃ§in araÅŸtÄ±rmam ve taramam gereken yeni ÅŸeyler var mÄ±?" diye dÃ¼ÅŸÃ¼n. EÄŸer cevap evetse devam et; Ancak bunu 3 kezden fazla yapma.
            4/ Kesinlikle uydurma bilgiler verme/yazma, sadece bulduÄŸun ve topladÄ±ÄŸÄ±n gerÃ§ek bilgileri yaz.
            5/ Nihai Ã§Ä±ktÄ±da, araÅŸtÄ±rmanÄ± desteklemek iÃ§in tÃ¼m referans verileri ve baÄŸlantÄ±larÄ± da yaz. 
            6/ Her zaman aÃ§Ä±k, anlaÅŸÄ±lÄ±r ve basit bir TÃ¼rkÃ§e ile cevap ver. """
)

agent_kwargs = {
    "extra_prompt_messages": [MessagesPlaceholder(variable_name="memory")],
    "system_message": system_message,
}

llm = ChatOpenAI(temperature=0, model="gpt-4-1106-preview")
memory = ConversationSummaryBufferMemory(
    memory_key="memory", return_messages=True, llm=llm, max_token_limit=1000)

agent_executor = initialize_agent(
    tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True, agent_kwargs=agent_kwargs,
    memory=memory,
)

# Agent'i Ã§aÄŸÄ±r
# agent_executor.invoke(
#     {
#         "input": "Leonardo dicaprio'nun mevcut kÄ±z arkadaÅŸÄ± kim? Onunla ne zaman sevgili oldu? KÄ±z kaÃ§ yaÅŸÄ±nda"
#     }
# )


def main():
    st.set_page_config(page_title="AraÅŸtÄ±rma AsistanÄ±", page_icon="ğŸ”")

    st.title("AraÅŸtÄ±rma AsistanÄ± ğŸ”")
    st.markdown("""
        Merak ettiÄŸiniz konuyu girin ve detaylÄ± araÅŸtÄ±rma sonuÃ§larÄ±nÄ± hemen alÄ±n.
    """)
    st.markdown("""
        Bu uygulama arka tarafta Google Search ve Langchain kullanarak sorduÄŸunuz veya araÅŸtÄ±rma konunusu iÃ§in internette araÅŸtÄ±rma yapar, bulduÄŸu sonuÃ§lar aratÄ±lan konu ile ilgili
        deÄŸilse baÅŸka kaynaklarÄ± tarar. Bu sayede sorduÄŸunuz soruya birden fazla kaynaklÄ± doÄŸru cevaplar verir. TÃ¼m bunlarÄ± Langhcain ile oluÅŸturulan iki farklÄ± AI Agent ile yapar.
        AyrÄ±ca eÄŸer ElevenLabs API Key girerseniz, bulduÄŸu sonucu seslendirir.     
        """)
    st.markdown("""
        UygulamanÄ±n Ã§alÄ±ÅŸabilmesi iÃ§in OpenAI ve SERP API Key girmek zorunlu, seslendirme istemezseniz Elevenlabs kÄ±smÄ±nÄ± boÅŸ bÄ±rakÄ±n.
        """)
    st.markdown("X'te bana ulaÅŸÄ±n: [**:blue[Giray]**](https://twitter.com/gryhkn)")

    # Ã¶rnek
    if 'init' not in st.session_state:
        st.session_state['init'] = True

        st.session_state['initial_text'] = """
        bir sÃ¼redir resmen hayat felsefesi yapÄ±lacak iki cÃ¼mle kafamda yankÄ±lanÄ±p duruyor.
        ilki carl jungâ€™tan:
        â€œdÃ¼nya sana kim olduÄŸunu soracak, eÄŸer cevabÄ± bilmiyorsan o sÃ¶yleyecek.â€
        ikincisi de david humeâ€™dan:
        â€œeÄŸer burada durup daha ileri gitmeyeceksek, niÃ§in bu noktaya kadar geldik?â€
        """
        st.session_state['initial_audio'] = "first wav carl.wav"  # Local ses dosyasÄ±nÄ±n yolu

    query = st.text_input("AraÅŸtÄ±rma Konusu", help="AraÅŸtÄ±rmak istediÄŸiniz konuyu buraya yazÄ±n.")
    search_button_clicked = st.button("Ara", key="search")
    st.divider()


    if search_button_clicked and query:
        # kullanÄ±cÄ± input
        with st.spinner(f"'{query}' iÃ§in araÅŸtÄ±rma yapÄ±lÄ±yor..."):
            result = agent_executor({"input": query})
            st.success("AraÅŸtÄ±rma tamamlandÄ±!")
            st.info(result['output'])
            if elevenlabs_api_key:
                audio = generate(
                    text=result['output'],
                    voice="Bella",
                    model='eleven_multilingual_v2'
                )
                st.audio(audio, format='audio/wav')
        st.session_state['init'] = False
    elif st.session_state['init']:
        st.text("Ã–RNEK:")
        # baÅŸlangÄ±Ã§ deÄŸerlerini gÃ¶ster
        st.markdown(st.session_state['initial_text'])
        st.audio(st.session_state['initial_audio'], format='audio/wav')

    st.sidebar.image("assistant.jpg", caption='')
    st.sidebar.info("Overwatch")

if __name__ == "__main__":
    main()

#extract_and_summarize_content("Montgisard Muharebesini kim kazanmÄ±ÅŸtÄ±r?", "https://tr.wikipedia.org/wiki/Montgisard_Muharebesi#:~:text=Montgisard%20Muharebesi%2C%20Eyyubiler%20ile%20Kud%C3%BCs,ile%20Selahattin%20Eyyubi'yi%20yenmi%C5%9Ftir.")
# web_search("Meta'nÄ±n yeni Thread uygulamasÄ± nedir?")